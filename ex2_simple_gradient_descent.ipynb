{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HFU87oU60rew",
        "outputId": "0c9eae32-4518-402d-a0aa-98ae6d5b1a3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 8)\n",
            "(16512,)\n",
            "(4128, 8)\n",
            "(4128,)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load dataset, split into training and test sets, and scale features\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "#from sklearn.datasets import load_boston\n",
        "california = datasets.fetch_california_housing(as_frame=False)\n",
        "#X, y = housing.data, housing.target\n",
        "# load boston housing price dataset\n",
        "\n",
        "x = california.data\n",
        "y = california.target\n",
        "\n",
        "# split into training and test sets, namely 80 percent of examples goes for the training, 20 percent goes for the test set\n",
        "N_train = int(0.8 * x.shape[0])\n",
        "x_train = x[:N_train,:]\n",
        "y_train = y[:N_train]\n",
        "x_test = x[N_train:,:]\n",
        "y_test = y[N_train:]\n",
        "\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train_std = np.std(x_train, axis=0)\n",
        "x_test_mean = np.mean(x_test, axis=0)\n",
        "x_test_std = np.std(x_test, axis=0)\n",
        "# scale features by removing mean and dividing by the standard deviation\n",
        "x_train_scaled = (x_train-x_train_mean)/x_train_std# YOUR CODE GOES HERE\n",
        "x_test_scaled = (x_test-x_test_mean)/x_test_std# YOUR CODE GOES HERE\n",
        "\n",
        "print(x_train_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test_scaled.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XDiE7zUN0rex",
        "outputId": "fcdf88ed-6403-40c4-d467-d0c13ef4a804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 9)\n",
            "(4128, 9)\n",
            "[[-0.17113857]\n",
            " [-1.98875547]\n",
            " [-1.11966981]\n",
            " [ 0.80779359]\n",
            " [-0.3283484 ]\n",
            " [ 2.61475695]\n",
            " [-0.28311532]\n",
            " [ 0.86005893]\n",
            " [-0.14972145]]\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Add intercept terms and initialize parameters\n",
        "# Note: If you run this step again, please run from step 1 because notebook keeps the value from the previous run\n",
        "x_train_scaled = np.concatenate((np.ones((x_train_scaled.shape[0], 1)), x_train_scaled), axis=1)\n",
        "x_test_scaled = np.concatenate((np.ones((x_test_scaled.shape[0], 1)), x_test_scaled), axis=1)\n",
        "\n",
        "print(x_train_scaled.shape)\n",
        "print(x_test_scaled.shape)\n",
        "\n",
        "\n",
        "# init parameters using random values\n",
        "theta = np.random.randn(x_train_scaled.shape[1], 1)# YOUR CODE GOES HERE\n",
        "print(theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Y-vqjuj0rey"
      },
      "outputs": [],
      "source": [
        "# Step 3: Implement the gradient and the cost function\n",
        "# In this step, you have to calculate the gradient. You can use the provided formula but the best way is to vectorize\n",
        "# that formula for efficiency\n",
        "def compute_gradient(x,y,theta):\n",
        "    # YOUR CODE GOES HERE\n",
        "    grad=(1/len(x)) * ((x.T) @(x @ theta-y))\n",
        "    return grad\n",
        "def compute_cost(x,y,theta):\n",
        "    # YOUR CODE GOES HERE\n",
        "    error = x @ theta - y\n",
        "    cost = (1/(2*len(x)))* np.dot(error.T, error)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape[1]"
      ],
      "metadata": {
        "id": "KnuUndA0eBf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qXyK7g80rey"
      },
      "outputs": [],
      "source": [
        "# Step 4: Verify the gradient value\n",
        "# In this step, you need to verify that the computed gradient is correct. The difference betweet the gradient and the\n",
        "# approximate gradient should be very small (~10^-18)\n",
        "def approximate_gradient(x,y,theta,epsilon):\n",
        "    n_features = x.shape[1]\n",
        "    app_grad = np.zeros(n_features)\n",
        "    for i in range(n_features):\n",
        "        e = np.zeros(theta.shape)\n",
        "        e[i] = epsilon\n",
        "        cost_plus = compute_cost(x, y, theta + e)\n",
        "        cost_minus = compute_cost(x, y, theta - e)\n",
        "        app_grad[i] = (cost_plus - cost_minus) / (2 * epsilon)# YOUR CODE GOES HERE\n",
        "    return app_grad\n",
        "\n",
        "grad = compute_gradient(x_train_scaled,y_train,theta)\n",
        "epsilon = 1e-4\n",
        "app_grad = approximate_gradient(x_train_scaled,y_train,theta,epsilon)\n",
        "print('Sum of gradient squared error: ',np.sum((grad - app_grad)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdRvFog60rey"
      },
      "outputs": [],
      "source": [
        "# Step 5: Try gradient descent algorithm with different learning rates\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "# try different values for the learning rate\n",
        "learning_rates = [0.001,0.003,0.01,0.03,0.1,0.3]\n",
        "\n",
        "# this matrix keeps the learned parameters\n",
        "theta_matrix = np.zeros((len(learning_rates),x_train_scaled.shape[1]))\n",
        "\n",
        "# number of training iterations\n",
        "N_iterations = 100\n",
        "\n",
        "# prepare to plot\n",
        "plt.subplot(111)\n",
        "\n",
        "# calculate cost value and update theta\n",
        "for indx,alpha in enumerate(learning_rates):\n",
        "    # keep the cost value for each training step\n",
        "    J = np.zeros(N_iterations)\n",
        "\n",
        "    # initialize new parameters using random distribution\n",
        "    theta = 0.5 * np.random.randn(x_train_scaled.shape[1])\n",
        "    for step in range(N_iterations):\n",
        "        # update theta\n",
        "        theta = # YOUR CODE GOES HERE\n",
        "\n",
        "        # save the value of theta\n",
        "        theta_matrix[indx,:] = theta\n",
        "\n",
        "        # calculate the cost on traing set\n",
        "        J[step] = # YOUR CODE GOES HERE\n",
        "    # plot cost function\n",
        "    plt.plot(J)\n",
        "plt.xlabel('Training step')\n",
        "plt.ylabel('Cost')\n",
        "plt.legend(('0.001','0.003','0.01','0.03','0.1','0.3'), loc='upper right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hjqxXw60rey"
      },
      "outputs": [],
      "source": [
        "# Step 6: Predict the price of house\n",
        "# You have to select the best theta you found\n",
        "theta = # YOUR CODE GOES HERE\n",
        "predict_price = # YOUR CODE GOES HERE\n",
        "\n",
        "# calculate the cost for the test set\n",
        "test_cost = # YOUR CODE GOES HERE\n",
        "print('test cost: ',test_cost)\n",
        "\n",
        "# plot the ground truth and the predicted\n",
        "x_axis = np.linspace(1,len(y_test),len(y_test))\n",
        "plt.plot(x_axis,y_test,'b',x_axis,predict_price,'r')\n",
        "plt.legend(('Ground truth','Predicted'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Iu5V1LbK0rey"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}