# -*- coding: utf-8 -*-
"""ex2_multivariate_linear_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b7NumdeeGYY7RWdfKmvve0GlbjA0JfnF
"""

### load data
# call the load_dat function to load X and Y from the corresponding input files
X = load_dat("ex2x.dat")
Y =  load_dat("ex2y.dat")
# get some statistics of the data
num_samples = X.shape[0] # get the first dimension of X (i.e. number of rows)
dim = X.shape[1] # get the second dimension of X (i.e. number of columns)
print('X (%d x %d)' %(num_samples, dim))
print('Y (%d)' %(num_samples))

from google.colab import drive
drive.mount('/content/drive')

import numpy as np # import numpy for matrix operations
### this function load data from .dat file
def load_dat(filename):
    with open(filename, 'r') as fin:
        lines = fin.readlines()
        dim = len(lines[0].strip().split())
        num_samples = len(lines)
        data = np.zeros((num_samples, dim))
        for i in range(num_samples):
            data[i, :] = np.array([float(x) for x in lines[i].strip().split()])
        return data

### add intercept term to all samples in X
X = np.concatenate((np.ones((num_samples, 1)), X), axis=1)### Your code here ###
Y = Y.reshape([-1,1])
print('X (%d x %d)' %(num_samples, dim + 1))
print('Y (%d x 1)' %(num_samples))

### main functions of multivariate linear regression
from numpy.linalg import inv
def pseudo_inverse(A):
    # The pseudo inverse:
    # Input: a matrix A
    # Output: the pseudo_inverse of A
    ### Your code here ###
    return inv(np.dot(A.T, A)) @ A.T


def sse(prediction,reference):
    # Calculate the sum of square error between the prediction and reference vectors
    ### Your code here ###
    return np.sum((prediction - reference) ** 2)
def MAE(prediction, reference):
    # Calculate the mean absolute error between the prediction and reference vectors
    mae = np.mean(np.abs(prediction - reference))
    return mae

!ls ../

!git init

### estimate beta
# call the pseudo_inverse to estimate beta from X and Y
beta =  pseudo_inverse(X) @ Y### Your code here
# print the estimated (learned) parameters
print(beta)

### evaluate the model
import matplotlib.pyplot as plt
# calculate the predicted scores
prediction = X @ beta ### Your code here
# calculate the sum of square error
error = sse(prediction, Y)
ave_error=error/len(Y)
print('Sum of average error: %f' %ave_error)
print('Sum of square error: %f' %error)
plt.xlabel('X')
plt.ylabel('Y')
plt.plot(X,Y,'bx',X,prediction,'rx')
plt.legend(('Original Data', 'prediction Data'), loc='lower right')
plt.show()



### Extra step
# generate synthetic scores
Ys = 3 * X[:,0] + 2 * X[:,1] + 0.5 * X[:,2] # generate Ys using a linear function of the features of X
# perform multivariate linear regression with X and Ys as inputs
beta_2 = pseudo_inverse(X) @ Ys ### Your code here
print('beta_2: ', beta_2)
# calculate the predicted scores
prediction_2 =  X @ beta_2### Your code here
# calculate the sum of square error
error_2 = sse(prediction_2, Ys)
print('Sum of square error: %f' %error_2)