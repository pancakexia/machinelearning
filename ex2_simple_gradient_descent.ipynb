{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HFU87oU60rew",
        "outputId": "ce4acc63-d922-46a5-d9c4-469d318a94c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 8)\n",
            "(16512,)\n",
            "(4128, 8)\n",
            "(4128,)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load dataset, split into training and test sets, and scale features\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "#from sklearn.datasets import load_boston\n",
        "california = datasets.fetch_california_housing(as_frame=False)\n",
        "#X, y = housing.data, housing.target\n",
        "# load boston housing price dataset\n",
        "\n",
        "x = california.data\n",
        "y = california.target\n",
        "\n",
        "# split into training and test sets, namely 80 percent of examples goes for the training, 20 percent goes for the test set\n",
        "N_train = int(0.8 * x.shape[0])\n",
        "x_train = x[:N_train,:]\n",
        "y_train = y[:N_train]\n",
        "x_test = x[N_train:,:]\n",
        "y_test = y[N_train:]\n",
        "\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train_std = np.std(x_train, axis=0)\n",
        "x_test_mean = np.mean(x_test, axis=0)\n",
        "x_test_std = np.std(x_test, axis=0)\n",
        "# scale features by removing mean and dividing by the standard deviation\n",
        "x_train_scaled = (x_train-x_train_mean)/x_train_std# YOUR CODE GOES HERE\n",
        "x_test_scaled = (x_test-x_test_mean)/x_test_std# YOUR CODE GOES HERE\n",
        "\n",
        "print(x_train_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test_scaled.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XDiE7zUN0rex",
        "outputId": "96caf1d9-842f-4180-a955-fe4a0c68f3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 10)\n",
            "(4128, 10)\n",
            "[[ 0.6227632 ]\n",
            " [-0.36025802]\n",
            " [ 1.32368945]\n",
            " [-0.7853527 ]\n",
            " [-0.70974507]\n",
            " [-0.99732841]\n",
            " [-1.10761125]\n",
            " [-1.35679806]\n",
            " [ 0.01499003]\n",
            " [-0.12272687]]\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Add intercept terms and initialize parameters\n",
        "# Note: If you run this step again, please run from step 1 because notebook keeps the value from the previous run\n",
        "x_train_scaled = np.concatenate((np.ones((x_train_scaled.shape[0], 1)), x_train_scaled), axis=1)\n",
        "x_test_scaled = np.concatenate((np.ones((x_test_scaled.shape[0], 1)), x_test_scaled), axis=1)\n",
        "\n",
        "print(x_train_scaled.shape)\n",
        "print(x_test_scaled.shape)\n",
        "\n",
        "\n",
        "# init parameters using random values\n",
        "theta = np.random.randn(x_train_scaled.shape[1], 1)# YOUR CODE GOES HERE\n",
        "print(theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_Y-vqjuj0rey"
      },
      "outputs": [],
      "source": [
        "# Step 3: Implement the gradient and the cost function\n",
        "# In this step, you have to calculate the gradient. You can use the provided formula but the best way is to vectorize\n",
        "# that formula for efficiency\n",
        "def compute_gradient(x,y,theta):\n",
        "    # YOUR CODE GOES HERE\n",
        "    grad=(1/len(x)) * ((x.T) @(x @ theta-y))\n",
        "    return grad\n",
        "def compute_cost(x,y,theta):\n",
        "    # YOUR CODE GOES HERE\n",
        "    cost=(1/(2*len(x)))@((x@theta-y)@(x@theta-y))\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_qXyK7g80rey",
        "outputId": "56c48979-1252-4724-c013-5a2e4b7a7b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "dot() missing 1 required positional argument: 'b'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9ddc8888d5a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mapp_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproximate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sum of gradient squared error: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mapp_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-9ddc8888d5a5>\u001b[0m in \u001b[0;36mapproximate_gradient\u001b[0;34m(x, y, theta, epsilon)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcost_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcost_minus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mapp_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcost_plus\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcost_minus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# YOUR CODE GOES HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-7730a1e1f464>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(x, y, theta)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# YOUR CODE GOES HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dot() missing 1 required positional argument: 'b'"
          ]
        }
      ],
      "source": [
        "# Step 4: Verify the gradient value\n",
        "# In this step, you need to verify that the computed gradient is correct. The difference betweet the gradient and the\n",
        "# approximate gradient should be very small (~10^-18)\n",
        "def approximate_gradient(x,y,theta,epsilon):\n",
        "    n_features = x.shape[1]\n",
        "    app_grad = np.zeros(n_features)\n",
        "    for i in range(n_features):\n",
        "        e = np.zeros(theta.shape)\n",
        "        e[i] = epsilon\n",
        "        cost_plus = compute_cost(x, y, theta + e)\n",
        "        cost_minus = compute_cost(x, y, theta - e)\n",
        "        app_grad[i] = (cost_plus - cost_minus) / (2 * epsilon)# YOUR CODE GOES HERE\n",
        "    return app_grad\n",
        "\n",
        "grad = compute_gradient(x_train_scaled,y_train,theta)\n",
        "epsilon = 1e-4\n",
        "app_grad = approximate_gradient(x_train_scaled,y_train,theta,epsilon)\n",
        "print('Sum of gradient squared error: ',np.sum((grad - app_grad)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdRvFog60rey"
      },
      "outputs": [],
      "source": [
        "# Step 5: Try gradient descent algorithm with different learning rates\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "# try different values for the learning rate\n",
        "learning_rates = [0.001,0.003,0.01,0.03,0.1,0.3]\n",
        "\n",
        "# this matrix keeps the learned parameters\n",
        "theta_matrix = np.zeros((len(learning_rates),x_train_scaled.shape[1]))\n",
        "\n",
        "# number of training iterations\n",
        "N_iterations = 100\n",
        "\n",
        "# prepare to plot\n",
        "plt.subplot(111)\n",
        "\n",
        "# calculate cost value and update theta\n",
        "for indx,alpha in enumerate(learning_rates):\n",
        "    # keep the cost value for each training step\n",
        "    J = np.zeros(N_iterations)\n",
        "\n",
        "    # initialize new parameters using random distribution\n",
        "    theta = 0.5 * np.random.randn(x_train_scaled.shape[1])\n",
        "    for step in range(N_iterations):\n",
        "        # update theta\n",
        "        theta = # YOUR CODE GOES HERE\n",
        "\n",
        "        # save the value of theta\n",
        "        theta_matrix[indx,:] = theta\n",
        "\n",
        "        # calculate the cost on traing set\n",
        "        J[step] = # YOUR CODE GOES HERE\n",
        "    # plot cost function\n",
        "    plt.plot(J)\n",
        "plt.xlabel('Training step')\n",
        "plt.ylabel('Cost')\n",
        "plt.legend(('0.001','0.003','0.01','0.03','0.1','0.3'), loc='upper right')\n",
        "plt.show()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hjqxXw60rey"
      },
      "outputs": [],
      "source": [
        "# Step 6: Predict the price of house\n",
        "# You have to select the best theta you found\n",
        "theta = # YOUR CODE GOES HERE\n",
        "predict_price = # YOUR CODE GOES HERE\n",
        "\n",
        "# calculate the cost for the test set\n",
        "test_cost = # YOUR CODE GOES HERE\n",
        "print('test cost: ',test_cost)\n",
        "\n",
        "# plot the ground truth and the predicted\n",
        "x_axis = np.linspace(1,len(y_test),len(y_test))\n",
        "plt.plot(x_axis,y_test,'b',x_axis,predict_price,'r')\n",
        "plt.legend(('Ground truth','Predicted'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Iu5V1LbK0rey"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}